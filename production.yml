# If you want to build PostgreSQL and Redis on here...
# Use the task definition for more container builds.
  # I recommend just using ElastiCache and RDS.
  # However, you can also get away with building everything
  # in the GitHub action.
  # I've left the images and Dockerfile locations in here instead
  # of deleting these.

version: '3'

#volumes:
#  production_postgres_data: {}
#  production_postgres_data_backups: {}

services:
  django: &django
    build:
      context: .
      dockerfile: compose/production/standalone/django/Dockerfile
    image: aws_ecs_deploy_production_django
#    Use Parameter Store or Secrets Manager.
#    env_file:
#      - ./.envs/.production/.django
#      - ./.envs/.production/.postgres
    command: /start

#  postgres:
#    build:
#      context: .
#      dockerfile: ./compose/production/postgres/Dockerfile
#    image: aws_ecs_deploy_production_postgres
#    volumes:
#      - production_postgres_data:/var/lib/postgresql/data
#      - production_postgres_data_backups:/backups
#    env_file:
#      - ./.envs/.production/.postgres
#  awscli:
#    build:
#      context: .
#      dockerfile: ./compose/production/aws/Dockerfile
#    env_file:
#      - ./.envs/.production/.django
#    volumes:
#      - production_postgres_data_backups:/backups

#  redis:
#    image: redis:5.0

  # You aren't using these in the Dockerfile. Trust me.
  # Read the FAQ section of README to find out how to
  # do the celery stuff
  celeryworker:
    <<: *django
    image: aws_ecs_deploy_production_celeryworker
    command: /start-celeryworker

  celerybeat:
    <<: *django
    image: aws_ecs_deploy_production_celerybeat
    command: /start-celerybeat

#  I don't recommend using Flower. If you use Flower,
  # you should just deploy to EC2 instead of ECS.
  # For EC2 deployment, just SSH and rsync your files over.
#  flower:
#    <<: *django
#    image: aws_ecs_deploy_production_flower
#    command: /start-flower
