# If you want to build PostgreSQL and Redis on here...
# Use the task definition for more container builds.
  # I recommend just using ElastiCache and RDS.
  # However, you can also get away with building everything
  # in the GitHub action.
  # I've left the images and Dockerfile locations in here instead
  # of deleting these.

version: '3'

volumes:
  production_postgres_data: {}
  production_postgres_data_backups: {}

services:
  django:
    build:
      context: .
      dockerfile: ./compose/production/ecs/django/Dockerfile
    image: aws_ecs_deploy_production_django
    env_file:
      - ./.envs/.production/.django
      - ./.envs/.production/.postgres
    command: /start

  nginx:
    build:
      context: .
      dockerfile: ./compose/production/ecs/nginx/Dockerfile
    image: aws_ecs_deploy_production_nginx
    ports:
    - "0.0.0.0:80:80"

  postgres:
    build:
      context: .
      dockerfile: ./compose/production/postgres/Dockerfile
    image: aws_ecs_deploy_production_postgres
    volumes:
      - production_postgres_data:/var/lib/postgresql/data
      - production_postgres_data_backups:/backups
    env_file:
      - ./.envs/.production/.postgres

  awscli:
    build:
      context: .
      dockerfile: ./compose/production/aws/Dockerfile
    env_file:
      - ./.envs/.production/.django
    volumes:
      - production_postgres_data_backups:/backups

  redis:
    image: redis:5.0

  # You aren't using these in the Dockerfile. Trust me.
  # Read the FAQ section of README to find out how to
  # do the celery stuff

  # I don't recommend using Flower. If you use Flower,
  # you should just deploy to ONE EC2 instance instead of ECS.
  # For EC2 deployment, just SSH and rsync your files over.
#  flower:
#    <<: *django
#    image: aws_ecs_deploy_production_flower
#    command: /start-flower
